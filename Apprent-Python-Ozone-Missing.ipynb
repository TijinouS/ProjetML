{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Gestion des données manquantes sur les données d'Ozone avec  <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>  <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 100px; display: inline\" alt=\"Scikit-learn\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**: \n",
    "- Création d'un jeu de données contenant des données manquantes à partir des données ozone \n",
    "- Visualisation des données manquantes \n",
    "- Comparaison de diverses méthodes de complétion pour les données quantitatives\n",
    "- Complétion avec MissForest de l'ensemble des données (quantitaives et qualitatives) et impact sur les résultats de classification relativement au jeu de données initial complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prise en charge des données </font>\n",
    "### Lesture des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont été extraites et mises en forme par le service concerné de Météo France. Elles sont décrites par les variables suivantes:\n",
    "\n",
    "* **JOUR** Le type de jour ; férié (1) ou pas (0) ;\n",
    "* **O3obs** La concentration d'ozone effectivement observée le lendemain à 17h locales correspondant souvent au maximum de pollution observée ;\n",
    "* **MOCAGE** Prévision de cette pollution obtenue par un modèle déterministe de mécanique des fluides (équation de Navier et Stockes);\n",
    "* **TEMPE** Température prévue par MétéoFrance pour le lendemain 17h ;\n",
    "* **RMH2O** Rapport d'humidité ;\n",
    "* **NO2** Concentration en dioxyde d'azote ;\n",
    "* **NO** Concentration en monoxyde d'azote ;\n",
    "* **STATION** Lieu de l'observation : Aix-en-Provence, Rambouillet, Munchhausen, Cadarache et Plan de Cuques ;\n",
    "* **VentMOD** Force du vent ;\n",
    "* **VentANG** Orientation du vent. \n",
    "\n",
    "Ce sont des données \"propres\", sans trous, bien codées et de petites tailles. Elles présentent avant tout un caractère pédagogique.\n",
    "\n",
    "Il est choisi ici de lire les données avec la librairie `pandas` pour bénéficier de la classe DataFrame. Ce n'est pas nécessaire pour l'objectif de prévision car les variables qualitatives ainsi construites ne peuvent être utilisées pour l'interprétation des modèles obtenus dans `scikit-learn` qui ne reconnaît pas la classe DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:10.756181Z",
     "start_time": "2019-11-18T09:19:10.033317Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Lecture des données\n",
    "## Charger les données ou les lire directement en précisant le chemin\n",
    "path=\"\"\n",
    "ozone=pd.read_csv(path+\"depSeuil.dat\",sep=\",\",header=0)\n",
    "# Vérification du contenu\n",
    "ozone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui suit permet d'affecter le bon type aux variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:10.784429Z",
     "start_time": "2019-11-18T09:19:10.762200Z"
    }
   },
   "outputs": [],
   "source": [
    "ozone[\"STATION\"]=pd.Categorical(ozone[\"STATION\"],ordered=False)\n",
    "ozone[\"JOUR\"]=pd.Categorical(ozone[\"JOUR\"],ordered=False)\n",
    "ozone[\"O3obs\"]=pd.DataFrame(ozone[\"O3obs\"], dtype=float)\n",
    "ozone.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:10.823473Z",
     "start_time": "2019-11-18T09:19:10.787257Z"
    }
   },
   "outputs": [],
   "source": [
    "ozone.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:11.275823Z",
     "start_time": "2019-11-18T09:19:11.264575Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt, log\n",
    "ozone[\"SRMH2O\"]=ozone[\"RMH2O\"].map(lambda x: sqrt(x))\n",
    "ozone[\"LNO2\"]=ozone[\"NO2\"].map(lambda x: log(x))\n",
    "ozone[\"LNO\"]=ozone[\"NO\"].map(lambda x: log(x))\n",
    "del ozone[\"RMH2O\"]\n",
    "del ozone[\"NO2\"]\n",
    "del ozone[\"NO\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:11.297416Z",
     "start_time": "2019-11-18T09:19:11.279311Z"
    }
   },
   "outputs": [],
   "source": [
    "ozone[\"DepSeuil\"]=ozone[\"O3obs\"].map(lambda x: x > 150)\n",
    "ozone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable à expliquer binaire\n",
    "Yb=ozone[\"DepSeuil\"].map(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des variables quantitatives et qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:20.610161Z",
     "start_time": "2019-11-18T09:19:20.594438Z"
    }
   },
   "outputs": [],
   "source": [
    "ozone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:19:20.645052Z",
     "start_time": "2019-11-18T09:19:20.611990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variables explicatives\n",
    "# On transforme les variables qualitatives en paquets d'indicatrice pour la phase d'apprentissage.\n",
    "\n",
    "ozoneDum=pd.get_dummies(ozone[[\"JOUR\",\"STATION\"]])\n",
    "del ozoneDum[\"JOUR_0\"]\n",
    "ozoneQuant=ozone[[\"MOCAGE\",\"TEMPE\",\"VentMOD\",\"VentANG\",\"SRMH2O\",\"LNO2\",\"LNO\"]]\n",
    "\n",
    "dfC=pd.concat([ozoneDum,ozoneQuant],axis=1)\n",
    "dfC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozoneQuant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Gestion des données manquantes](http://wikistat.fr/pdf/st-m-app-idm.pdf)\n",
    "Les vraies données sont le plus souvent mitées par l'absence de données, conséquences d'erreurs de saisie, de pannes de capteurs... Les librairies de Python (`pandas`) offrent des choix rudimentaires pour faire des imputations de données manquantes quand celles-ci le sont de façon complètement aléatoire. \n",
    "\n",
    "Le calepin R d'analyse de ces mêmes données propose une comparaison assez détaillée de deux stratégiées afin d'évaluer leurs performances respectives. \n",
    "\n",
    "La **première stratégie** commence par imputer les données manquantes en les prévoyant par l'algorithme `missForest`. Une fois les données manquantes imputées, on utilise les forêts aléatoires pour construire un algorithme de prédiction du dépassement du seuil.\n",
    "\n",
    "La **deuxième stratégie** évite l'étape d'imputation en exécutant directement un algorithme de prévision tolérant des données manquantes. Peu le font, c'est le cas de `XGBoost`.\n",
    "\n",
    "Sur ces données, mais sans gros effort d'optimisation de `XGBoost`, la première stratégie enchaînant `missForest` puis `randomForest` conduit à de meilleurs résultats. Seule celle-ci est employée dans ce calepin mais, bien évidemment, l'exécution de `xgboost` sans imputation préalable est une option également possible en Python.\n",
    "\n",
    "Bien moins de méthodes sont proposées en Python, `Scikit-learn` ne proposant que des imputations basiques par la moyenne ou la médiane comme dans `pandas`. Néanmoins une imputation par prévision utilisant *k*-nn,  ou des forêts aléatoires (Missforest) est disponible dans la librairie `sklearn.impute`. Le souci est que Python ne gère pas bien les deux types de variables : quantitatives et qualitatives. Pour simplifier dans ce TP, nous allons donc ne considérer des données manquantes que dans les variables quantitatives. \n",
    "\n",
    "Les commandes ci-dessous font appel aux fichiers suivants:\n",
    "- `X` données complètes initiales : **ozoneQuant**\n",
    "- `Xna` les données avec des trous, \n",
    "- `XnaImp` les données avec imputations \n",
    "\n",
    "\n",
    "### Préparation des trous dans `ozone`\n",
    "Les variables explicatives quantitatives de la base `ozone` sont reprises. La première opération consiste à générer aléatoirement un certain taux de données manquantes par la fonction définie ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T14:54:34.117257Z",
     "start_time": "2019-07-03T14:54:34.110315Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import random\n",
    "\n",
    "def input_nan(x, tx):\n",
    "    \"\"\"\n",
    "    x : a 2D matrix of float dtype\n",
    "    tx: the rate of nan value to put in the matrix\n",
    "    \"\"\"\n",
    "    n_total = x.shape[0] * x.shape[1]\n",
    "    mask = np.array([random.random() for _ in range(n_total)]).reshape(x.shape)<tx\n",
    "    mx = ma.masked_array(x, mask=mask, fill_value=np.nan)\n",
    "    return mx.filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T14:54:35.714762Z",
     "start_time": "2019-07-03T14:54:35.707142Z"
    }
   },
   "outputs": [],
   "source": [
    "# données initiales \n",
    "X=ozoneQuant \n",
    "# Génération de 30% de valeurs manquantes\n",
    "Xna=input_nan(X, .3)\n",
    "\n",
    "Xna_df = pd.DataFrame(Xna, columns=ozoneQuant.columns)\n",
    "\n",
    "Xna_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(Xna)\n",
    "missing_rates = 1-Xna_df.count(axis=0)/nrows\n",
    "missing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_rates.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation  des données manquantes\n",
    "\n",
    "### Imputation simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_mean = SimpleImputer().fit_transform(Xna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Regarder quelles sont les options proposées par SimpleImputer. Quelle est l'option par défaut utilisée ci dessus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meanImp=pd.DataFrame(X_mean, columns=ozoneQuant.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meanImp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Sur la variable 'Température', reprendre l'analyse qui avait été faite en R : boxplot des erreurs d'imputation avec les diverses méthodes (moyenne, médiane, ..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation avec KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import  KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_kNN = knn_imputer.fit_transform(Xna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kNNImp=pd.DataFrame(X_kNN, columns=ozoneQuant.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kNNImp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation par `missForest`\n",
    "\n",
    "L'estimateur *ExtraTreesRegressor* entraîne une forêt aléatoire itérative et imite *missForest* dans R. *ExtraTreesRegressor* ajuste un certain nombre d'arbres aléatoires  et calcule la moyenne des résultats. Il provient du module sklearn.ensemble. Ses principaux arguments sont le nombre d'arbres dans la forêt et l'état aléatoire qui permet de contrôler les sources d'aléa.  Regarder l'aide pour plus de précisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rf = ExtraTreesRegressor(n_estimators=20, random_state=0)\n",
    "X_rf = IterativeImputer(estimator=estimator_rf, random_state=0, max_iter=300).fit_transform(Xna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfImp=pd.DataFrame(X_rf, columns=ozoneQuant.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfImp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozoneQuant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des erreurs de prévision par forêt aléatoire\n",
    "Prévision du dépassement d'ozone sans données manquantes et avec données manquantes imputées. Comparaison des erreurs de prévision sur l'échantillon test. Les valeurs par défaut des paramètres sont conservées. \n",
    "### Prévision sans données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extractions des échantillons d'apprentissage  et test. Comme le générateur est initalisé de façon identique, ce sont les mêmes échantillons dans les deux cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train,X_test,Yb_train,Yb_test=train_test_split(dfC,Yb,test_size=200,random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "Xr_train = scaler.transform(X_train)  \n",
    "# Meme transformation sur le test\n",
    "Xr_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T15:09:03.941566Z",
     "start_time": "2019-07-03T15:09:03.362895Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# prévision sans trous\n",
    "forest = RandomForestClassifier(n_estimators=500)\n",
    "# apprentissage\n",
    "rfFit = forest.fit(Xr_train,Yb_train)\n",
    "# erreur de prévision\n",
    "# erreur de prévision sur le test\n",
    "1-rfFit.score(Xr_test,Yb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision après imputation des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCImp=pd.concat([ozoneDum,X_rfImp],axis=1)\n",
    "dfCImp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "XnaImp_train,XnaImp_test,Yb_train,Yb_test=train_test_split(dfCImp,Yb,test_size=200,random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "Xr_train = scaler.transform(XnaImp_train)  \n",
    "# Meme transformation sur le test\n",
    "Xr_test = scaler.transform(XnaImp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T15:09:05.304552Z",
     "start_time": "2019-07-03T15:09:04.733321Z"
    }
   },
   "outputs": [],
   "source": [
    "# prévision avec trous imputés\n",
    "forest = RandomForestClassifier(n_estimators=500)\n",
    "# apprentissage\n",
    "rfFit = forest.fit(XnaImp_train,Yb_train)\n",
    "# erreur de prévision\n",
    "# erreur de prévision sur le test\n",
    "1-rfFit.score(XnaImp_test,Yb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire de la qualité de prévision avec 30% de données manquantes ? Comparer avec ce qui est obtenu pour les autres types d'imputation.\n",
    "\n",
    "Faites varier ce taux et étudiez la dégradation de la prévision.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "333.133px",
    "left": "528px",
    "top": "179.283px",
    "width": "231.05px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
